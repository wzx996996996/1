#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¡¥å…… PR commit ä¿®æ”¹è¡Œæ•°ä¿¡æ¯ (å¤šçº¿ç¨‹ç‰ˆ)
- ä» pr_commit_data è¡¨å– PR/commit
- è°ƒ GitHub API è·å–å¢åˆ è¡Œæ•°
- å†™å…¥ pr_commit_with_stats é›†åˆ
- æœ€åå¯¼å‡º CSV
"""

import csv
import time
import requests
import os
from pymongo import MongoClient
from itertools import cycle
from concurrent.futures import ThreadPoolExecutor, as_completed

# ========== é…ç½® ==========
MONGO_URI = "mongodb://localhost:27017/"
DB_NAME = "github"
SRC_COLLECTION = "pr_commit_data"         # åŸå§‹ PR è¡¨
DST_COLLECTION = "pr_commit_with_stats"   # æ–°è¡¨ï¼Œå¸¦å¢åˆ è¡Œæ•°
CSV_OUTPUT = "pr_commit_with_stats.csv"   # å¯¼å‡ºçš„ CSV æ–‡ä»¶
MAX_WORKERS = 10                          # å¹¶å‘çº¿ç¨‹æ•°

# ä½¿ç”¨ç¯å¢ƒå˜é‡è¯»å– GitHub Tokensï¼ˆé€—å·åˆ†éš”ï¼‰
TOKENS = [t.strip() for t in os.getenv("GITHUB_TOKENS", "").split(",") if t.strip()]
if not TOKENS:
    raise RuntimeError("æœªé…ç½® GITHUB_TOKENS ç¯å¢ƒå˜é‡ï¼ˆé€—å·åˆ†éš”å¤šä¸ª tokenï¼‰")

# ========== åˆå§‹åŒ– ==========
client = MongoClient(MONGO_URI)
db = client[DB_NAME]
src = db[SRC_COLLECTION]
dst = db[DST_COLLECTION]
token_cycle = cycle(TOKENS)


def github_get(url):
    """è½®æ¢ Token è°ƒ GitHub API"""
    for _ in range(len(TOKENS)):
        token = next(token_cycle)
        headers = {"Authorization": f"token {token}"}
        r = requests.get(url, headers=headers)
        if r.status_code == 200:
            return r.json()
        elif r.status_code == 403:  # API é€Ÿç‡é™åˆ¶
            print("â³ Token hit rate limit, switching...")
            time.sleep(2)
            continue
        else:
            print(f"âŒ Error {r.status_code} for {url}")
            return None
    return None


def process_one(doc):
    """å¤„ç†å•ä¸ª PR commit"""
    repo = doc["Repo"]
    sha = doc["Commit SHA"]

    # å·²ç»æœ‰æ•°æ®å°±è·³è¿‡
    if dst.find_one({"Repo": repo, "Commit SHA": sha}):
        return None

    url = f"https://api.github.com/repos/{repo}/commits/{sha}"
    data = github_get(url)
    if not data:
        return None

    additions = data.get("stats", {}).get("additions", 0)
    deletions = data.get("stats", {}).get("deletions", 0)
    files = [f["filename"] for f in data.get("files", [])] if "files" in data else []

    new_doc = {
        "Repo": repo,
        "PR Number": doc.get("PR Number"),
        "Commit SHA": sha,
        "Author": doc.get("Author"),
        "Commit Date": doc.get("Commit Date"),
        "External Repo": doc.get("External Repo"),
        "Additions": additions,
        "Deletions": deletions,
        "Changed Files": files,
    }

    dst.insert_one(new_doc)
    print(f"âœ… {repo}@{sha} +{additions}/-{deletions}")
    return new_doc


def process_commits():
    docs = list(src.find())
    results = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_doc = {executor.submit(process_one, doc): doc for doc in docs}
        for future in as_completed(future_to_doc):
            try:
                result = future.result()
                if result:
                    results.append(result)
            except Exception as e:
                print(f"âŒ Error: {e}")
    return results


def export_csv():
    cursor = dst.find()
    with open(CSV_OUTPUT, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([
            "Repo", "PR Number", "Commit SHA", "Author", "Commit Date",
            "External Repo", "Additions", "Deletions", "Changed Files"
        ])
        for doc in cursor:
            writer.writerow([
                doc.get("Repo"),
                doc.get("PR Number"),
                doc.get("Commit SHA"),
                doc.get("Author"),
                doc.get("Commit Date"),
                doc.get("External Repo"),
                doc.get("Additions", 0),
                doc.get("Deletions", 0),
                ";".join(doc.get("Changed Files", []))
            ])
    print(f"ğŸ“„ CSV å¯¼å‡ºå®Œæˆ: {CSV_OUTPUT}")


if __name__ == "__main__":
    process_commits()
    export_csv()
