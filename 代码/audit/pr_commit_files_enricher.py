#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¡¥å…… PR commit ä¿®æ”¹è¡Œæ•° & æ–‡ä»¶çº§åˆ«è¯¦æƒ… (æ–­ç‚¹ç»­è·‘ç‰ˆï¼Œä¿ç•™åŸå§‹ _id)
- ä» pr_commit_data è¡¨å– PR/commit
- è°ƒ GitHub API è·å–å®Œæ•´ commit stats + files ä¿®æ”¹è¯¦æƒ…
- ä¿ç•™åŸæœ‰å­—æ®µ (_id, Repo, PR Number, Commit SHA, Author, Commit Date, External Repo)
- å­˜å…¥ pr_commit_with_stats é›†åˆ
- æ”¯æŒæ–­ç‚¹ç»­è·‘ï¼Œå¤±è´¥ä¼šé‡è¯•
"""

import csv
import time
import requests
import os
from pymongo import MongoClient
from itertools import cycle
from concurrent.futures import ThreadPoolExecutor, as_completed
from requests.exceptions import SSLError, ConnectionError

# ========== é…ç½® ==========
MONGO_URI = "mongodb://localhost:27017/"
DB_NAME = "github"
SRC_COLLECTION = "pr_commit_data"         # åŸå§‹ PR è¡¨
DST_COLLECTION = "new_pr_commit_with_stats"   # æ–°è¡¨ï¼Œå¸¦è¯¦ç»†ä¿®æ”¹
CSV_OUTPUT = "pr_commit_with_stats.csv"   # å¯¼å‡ºçš„ CSV æ–‡ä»¶
MAX_WORKERS = 10                          # å¹¶å‘çº¿ç¨‹æ•°
MAX_RETRIES = 5                           # æœ€å¤§é‡è¯•æ¬¡æ•°
RETRY_DELAY = 5                           # æ¯æ¬¡é‡è¯•å»¶è¿Ÿç§’æ•°

TOKENS = [t.strip() for t in os.getenv("GITHUB_TOKENS", "").split(",") if t.strip()]
if not TOKENS:
    raise RuntimeError("æœªé…ç½® GITHUB_TOKENS ç¯å¢ƒå˜é‡ï¼ˆé€—å·åˆ†éš”å¤šä¸ª tokenï¼‰")

# ========== åˆå§‹åŒ– ==========
client = MongoClient(MONGO_URI)
db = client[DB_NAME]
src = db[SRC_COLLECTION]
dst = db[DST_COLLECTION]
token_cycle = cycle(TOKENS)


def github_get(url):
    """è½®æ¢ Token è°ƒ GitHub APIï¼Œå¸¦é‡è¯•"""
    for attempt in range(MAX_RETRIES):
        for _ in range(len(TOKENS)):
            token = next(token_cycle)
            headers = {"Authorization": f"token {token}"}
            try:
                r = requests.get(url, headers=headers, timeout=30)
                if r.status_code == 200:
                    return r.json()
                elif r.status_code == 403:  # API é€Ÿç‡é™åˆ¶
                    print("â³ Token hit rate limit, switching...")
                    time.sleep(2)
                    continue
                else:
                    print(f"âŒ Error {r.status_code} for {url}")
                    return None
            except (SSLError, ConnectionError) as e:
                print(f"âš ï¸ ç½‘ç»œé”™è¯¯: {e}, é‡è¯• {attempt+1}/{MAX_RETRIES}")
                time.sleep(RETRY_DELAY)
                continue
    return None


def process_one(doc):
    """å¤„ç†å•ä¸ª PR commit"""
    repo = doc["Repo"]
    sha = doc["Commit SHA"]

    # å·²ç»æœ‰æ•°æ®å°±è·³è¿‡ (æ–­ç‚¹ç»­è·‘å…³é”®ç‚¹)
    if dst.find_one({"_id": doc["_id"]}):
        return None

    url = f"https://api.github.com/repos/{repo}/commits/{sha}"
    data = github_get(url)
    if not data:
        return None

    additions = data.get("stats", {}).get("additions", 0)
    deletions = data.get("stats", {}).get("deletions", 0)

    files_info = []
    for f in data.get("files", []):
        files_info.append({
            "filename": f.get("filename"),
            "status": f.get("status"),
            "additions": f.get("additions", 0),
            "deletions": f.get("deletions", 0),
            "changes": f.get("changes", 0),
            "patch": f.get("patch"),
        })

    new_doc = {
        "_id": doc["_id"],  # ä¿ç•™åŸå§‹ ID
        "Repo": repo,
        "PR Number": doc.get("PR Number"),
        "Commit SHA": sha,
        "Author": doc.get("Author"),
        "Commit Date": doc.get("Commit Date"),
        "External Repo": doc.get("External Repo"),
        "Additions": additions,
        "Deletions": deletions,
        "Files": files_info
    }

    dst.replace_one({"_id": doc["_id"]}, new_doc, upsert=True)
    print(f"âœ… {repo}@{sha} +{additions}/-{deletions}, files={len(files_info)}")
    return new_doc


def process_commits():
    docs = list(src.find())
    results = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_doc = {executor.submit(process_one, doc): doc for doc in docs}
        for future in as_completed(future_to_doc):
            try:
                result = future.result()
                if result:
                    results.append(result)
            except Exception as e:
                print(f"âŒ Error: {e}")
    return results


def export_csv():
    cursor = dst.find()
    with open(CSV_OUTPUT, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([
            "_id", "Repo", "PR Number", "Commit SHA", "Author", "Commit Date",
            "External Repo", "File", "Status", "Additions", "Deletions", "Changes"
        ])
        for doc in cursor:
            for f in doc.get("Files", []):
                writer.writerow([
                    str(doc.get("_id")),
                    doc.get("Repo"),
                    doc.get("PR Number"),
                    doc.get("Commit SHA"),
                    doc.get("Author"),
                    doc.get("Commit Date"),
                    doc.get("External Repo"),
                    f.get("filename"),
                    f.get("status"),
                    f.get("additions", 0),
                    f.get("deletions", 0),
                    f.get("changes", 0),
                ])
    print(f"ğŸ“„ CSV å¯¼å‡ºå®Œæˆ: {CSV_OUTPUT}")


if __name__ == "__main__":
    process_commits()
    export_csv()
